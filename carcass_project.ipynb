{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMRitKkwj2P10Baz62h2oZp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/holoho/section-project/blob/main/carcass_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders\n",
        "!pip install xgboost\n",
        "!pip install -U imbalanced-learn\n",
        "!pip install scikit-multilearn\n",
        "!pip install beautifultable"
      ],
      "metadata": {
        "id": "cMeWy4psC6qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USDjN0EB_XId"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# Mount your Google Drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Open the text file in read mode\n",
        "with open('/content/drive/MyDrive/QC_Type_carcass.txt', 'r') as file:\n",
        "    # Read the contents of the file into a list of lines\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Open a new CSV file in write mode\n",
        "with open('/content/drive/MyDrive/QC_Type_carcass.csv', 'w', newline='') as csv_file:\n",
        "    # Create a CSV writer object\n",
        "    writer = csv.writer(csv_file)\n",
        "\n",
        "    # Iterate over the lines and write them to the CSV file\n",
        "    for line in lines:\n",
        "        writer.writerow(line.split())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "pxYiYRLP_tvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read new csv file\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/QC_Type_carcass.csv\", header=None)"
      ],
      "metadata": {
        "id": "DgrvVXyR_xIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rename columns\n",
        "df.columns = ['arn','FarmID','Byr','Syr','iSage','idiff', 'type1', 'type2', 'type3', 'type4', 'type5', 'type6',\n",
        "       'type7', 'type8', 'type9', 'type10', 'type11', 'type12', 'type13',\n",
        "       'type14', 'type15', 'type16', 'type17', 'type18', 'type19',\"grad1\",\"grad2\",\"grad3\",\"grad4\",\"grad5\",\"grad6\", 'FS', 'P_CW',\n",
        "       'P_EMA', 'P_BF', 'P_MS', 'P_Tprice','CW',\n",
        "       'EMA', 'BF', 'MS', 'Tprice']"
      ],
      "metadata": {
        "id": "9IePkBqo_5s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop unnecessary columns\n",
        "dfn = df.drop(columns = ['arn','FarmID','Byr','Syr','iSage','idiff',\"grad1\",\"grad2\",\"grad3\",\"grad4\",\"grad5\",\"grad6\",'P_CW','P_EMA', 'P_BF', 'P_MS', 'P_Tprice'])"
      ],
      "metadata": {
        "id": "S-IwnWZ9_97K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check types of columns\n",
        "dfn.info()"
      ],
      "metadata": {
        "id": "_wXiNR8rAOJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace all '.' to null values\n",
        "dfn.replace({'.': None}, inplace=True)"
      ],
      "metadata": {
        "id": "6HduTjWGAVW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete all null values\n",
        "dfn = dfn.dropna()"
      ],
      "metadata": {
        "id": "4CZnvM3PAXX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confirm values\n",
        "dfn"
      ],
      "metadata": {
        "id": "CIwxl-TIAoS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index 재정렬(초기화)\n",
        "df1 = dfn.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "4tARSlxaAvxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "2ud6puMiAxJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change all features to object\n",
        "df1.iloc[:, 0:18] = df1.iloc[:, 0:18].astype('object')"
      ],
      "metadata": {
        "id": "CVgorXKVbmtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "RqRz0mBwcJu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change all objects to float64\n",
        "df1 = df1.astype('float64')"
      ],
      "metadata": {
        "id": "bZyM8TspA0oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "L91LF3x7BDs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target value \n",
        "\n",
        "CW, EMA, BF, MS, Tprice 구간 분할"
      ],
      "metadata": {
        "id": "AfDQkvBqBSUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CW 분할 구간(divided by 9 equally)\n",
        "cnt, bins = np.histogram(df1.CW, bins=9)\n",
        "print(cnt)\n",
        "print(bins)\n",
        "\n",
        "df1['cw_bins']=pd.cut(x=df1.CW,bins=bins,\n",
        "                     labels=['1','2','3','4','5','6','7','8','9'],\n",
        "                     include_lowest=True)\n",
        "\n",
        "# EMA 구간 분할\n",
        "cnt, bins = np.histogram(df1.EMA, bins=9)\n",
        "print(cnt)\n",
        "print(bins)\n",
        "df1['ema_bins']=pd.cut(x=df1.EMA,bins=bins,\n",
        "                     labels=['1','2','3','4','5','6','7','8','9'],\n",
        "                     include_lowest=True)\n",
        "\n",
        "# BF 구간 분할\n",
        "cnt, bins = np.histogram(df1.BF, bins=9)\n",
        "df1['bf_bins']=pd.cut(x=df1.BF,bins=bins,\n",
        "                     labels=['1','2','3','4','5','6','7','8','9'],\n",
        "                     include_lowest=True)\n",
        "\n",
        "# MS 구간 분할\n",
        "cnt, bins = np.histogram(df1.MS, bins=9)\n",
        "df1['ms_bins']=pd.cut(x=df1.MS,bins=bins,\n",
        "                     labels=['1','2','3','4','5','6','7','8','9'],\n",
        "                     include_lowest=True)\n",
        "\n",
        "# Tprice 구간 분할\n",
        "cnt, bins = np.histogram(df1.Tprice, bins=9)\n",
        "df1['tp_bins']=pd.cut(x=df1.Tprice,bins=bins,\n",
        "                     labels=['1','2','3','4','5','6','7','8','9'],\n",
        "                     include_lowest=True)"
      ],
      "metadata": {
        "id": "X6QPmvw5BFaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.cw_bins"
      ],
      "metadata": {
        "id": "7SNKjsqCB5Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# csv 저장(backup)\n",
        "df1.to_csv(\"/content/drive/MyDrive/output.csv\")"
      ],
      "metadata": {
        "id": "FCeGQTwJCpiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import seaborn library\n",
        "import seaborn as sns\n",
        "\n",
        "# Get correlation matrix of the meat DataFrame\n",
        "corr = df1.corr(method='spearman')\n",
        "\n",
        "plt.figure(figsize = (30,24))\n",
        "# Customize the heatmap of the corr_meat correlation matrix\n",
        "sns.heatmap(corr,\n",
        "            annot=True,\n",
        "            linewidths=0.4,\n",
        "            annot_kws={\"size\": 10})\n",
        "\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0) \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gLFCRU7gB9BT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 분할된 CW 분포표 \n",
        "fig, ax=plt.subplots(1,2,figsize=(15,6))\n",
        "_ = sns.countplot(x='cw_bins', data=df1, ax=ax[0])\n",
        "_ = df1['cw_bins'].value_counts().plot.pie(autopct=\"%1.1f%%\", ax=ax[1])"
      ],
      "metadata": {
        "id": "NqnSsv39CAC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 분할된 CW 분포표 \n",
        "fig, ax=plt.subplots(1,2,figsize=(15,6))\n",
        "_ = sns.countplot(x='ema_bins', data=df1, ax=ax[0])\n",
        "_ = df1['ema_bins'].value_counts().plot.pie(autopct=\"%1.1f%%\", ax=ax[1])"
      ],
      "metadata": {
        "id": "xKvsy_r5jaHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 분할된 BF 분포표 \n",
        "fig, ax=plt.subplots(1,2,figsize=(15,6))\n",
        "_ = sns.countplot(x='bf_bins', data=df1, ax=ax[0])\n",
        "_ = df1['bf_bins'].value_counts().plot.pie(autopct=\"%1.1f%%\", ax=ax[1])"
      ],
      "metadata": {
        "id": "3KAMjJqfCKxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 분할된 MS 분포표 \n",
        "fig, ax=plt.subplots(1,2,figsize=(15,6))\n",
        "_ = sns.countplot(x='ms_bins', data=df1, ax=ax[0])\n",
        "_ = df1['ms_bins'].value_counts().plot.pie(autopct=\"%1.1f%%\", ax=ax[1])"
      ],
      "metadata": {
        "id": "EcYDa1RdCRya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 분할된 Tprice 분포표 \n",
        "fig, ax=plt.subplots(1,2,figsize=(15,6))\n",
        "_ = sns.countplot(x='tp_bins', data=df1, ax=ax[0])\n",
        "_ = df1['tp_bins'].value_counts().plot.pie(autopct=\"%1.1f%%\", ax=ax[1])"
      ],
      "metadata": {
        "id": "rUdN-vJvCSNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 column별 분포표표\n",
        "df1.plot(kind=\"density\", layout=(6,5), subplots=True,sharex=False, sharey=False, figsize=(15,15))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JwSGztKCCeQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read csv \n",
        "df = pd.read_csv(\"/content/drive/MyDrive/output.csv\")"
      ],
      "metadata": {
        "id": "Xr_ULqjmDJ_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#결측치 확인\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "zEx3ruXEDSNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first row delete\n",
        "df = df.drop(columns = 'Unnamed: 0') "
      ],
      "metadata": {
        "id": "EbblvZ21DXKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#결측치 재확인\n",
        "[(x, df[x].isnull().sum()) for x in df.columns if df[x].isnull().any()]"
      ],
      "metadata": {
        "id": "b1rbvwmuCyJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#중복값 확인\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "VjsasZKSDggz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check values and dtype\n",
        "df.info()"
      ],
      "metadata": {
        "id": "EdwHbaKQDhK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. target values를 한번에 이용한 분류 모델\n",
        " \n",
        " = Multiclass-multioutput process"
      ],
      "metadata": {
        "id": "uU3WSL7nDuEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, :19] # 20 features\n",
        "Y= df.iloc[:, 25:]  # 5 targets"
      ],
      "metadata": {
        "id": "9Iu5WBUPEI2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2) # train: test = 8:2"
      ],
      "metadata": {
        "id": "hdyUDgPYEP5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MultiOutput - RandomForest Classification\n",
        "# 알고리즘 참고: https://scikit-learn.org/stable/modules/multiclass.html  \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "forest = RandomForestClassifier(n_estimators = 10, random_state=42)\n",
        "multi_target_forest = MultiOutputClassifier(forest, n_jobs=-1)\n",
        "multi_target_forest.fit(X_train, y_train)\n",
        "multi_target_forest.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "print(\"the result of MutliOutput-classification-using-RandomForest\")\n",
        "print('the mean accuracy on the given train data and labels %10.9f'% multi_target_forest.score(X_train, y_train))\n",
        "print('the mean accuracy on the given test data and labels %10.9f'% multi_target_forest.score(X_test, y_test)) "
      ],
      "metadata": {
        "id": "6HqAnkN1EXVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = multi_target_forest.predict(X_test)\n",
        "prediction.shape"
      ],
      "metadata": {
        "id": "7rbS3JHoEjxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. target value를 하나씩 이용한 분류 모델\n",
        " \n",
        " = Multiclass classification\n",
        "\n",
        " 1) One vs Rest Classifier\n",
        "\n",
        " 2) One vs One Classifier\n",
        "\n",
        " 3) OutputCode Classifier"
      ],
      "metadata": {
        "id": "nvhhl3uHE7UK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reset targets and features\n",
        "X = df.iloc[:, 0:19] # 20 features \n",
        "y= df.iloc[:, 25] # target cw_bins"
      ],
      "metadata": {
        "id": "3WQvN7yyE0KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# features ordinal encoder\n",
        "x_o = df.iloc[:, :19]\n",
        "oe = OrdinalEncoder()\n",
        "x = oe.fit_transform(x_o)\n",
        "def enc(array, frame):\n",
        "    for idx in range(array.shape[1]):\n",
        "        X_Exunique =sorted(frame.loc[:,frame.columns[idx]].unique())\n",
        "        X_ExTunique = np.unique(array[:,idx])\n",
        "        encode = dict(zip(X_Exunique, X_ExTunique))\n",
        "        print(encode)\n",
        "enc(x, x_o)\n",
        "\n",
        "# target CW label encoder\n",
        "y_la = df.iloc[:, 25]\n",
        "le = LabelEncoder()\n",
        "y_t = le.fit_transform(y_la)\n",
        "\n",
        "y_Exunique = np.unique(y_la)\n",
        "y_ExTunique = np.unique(y_t)\n",
        "y_encode = dict(zip(y_Exunique, y_ExTunique))\n",
        "print(y_encode)"
      ],
      "metadata": {
        "id": "L5HcMX2F738s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y_t, test_size=0.2)"
      ],
      "metadata": {
        "id": "-djRHg7KFsdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One vs Rest classifier - logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "model = LogisticRegression()\n",
        "model_log = OneVsRestClassifier(model)\n",
        "model_log.fit(X_train, y_train)\n",
        "\n",
        "y_predict_train_logreg = model_log.predict(X_train)\n",
        "y_predict_test_logreg = model_log.predict(X_test)\n",
        "\n",
        "train_accuracy_score_logreg = accuracy_score(y_train, y_predict_train_logreg)\n",
        "test_accuracy_score_logreg = accuracy_score(y_test, y_predict_test_logreg)\n",
        "\n",
        "print(train_accuracy_score_logreg)\n",
        "print(test_accuracy_score_logreg)"
      ],
      "metadata": {
        "id": "QgMOKKnPF2vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One vs Rest classifier - Random Forest\n",
        "model = RandomForestClassifier()\n",
        "model_rf = OneVsRestClassifier(model)\n",
        "model_rf.fit(X_train, y_train)\n",
        "\n",
        "y_predict_train_rf = model_rf.predict(X_train)\n",
        "y_predict_test_rf = model_rf.predict(X_test)\n",
        "\n",
        "train_accuracy_score_rf = accuracy_score(y_train, y_predict_train_rf)\n",
        "test_accuracy_score_rf = accuracy_score(y_test, y_predict_test_rf)\n",
        "\n",
        "print(train_accuracy_score_rf)\n",
        "print(test_accuracy_score_rf)"
      ],
      "metadata": {
        "id": "TqIZE9FxGCV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One vs Rest classifier - SVC\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "clf = OneVsRestClassifier(LinearSVC(random_state=42))\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_predict_train_clf = clf.predict(X_train)\n",
        "y_predict_test_clf = clf.predict(X_test)\n",
        "\n",
        "train_accuracy_score_clf = accuracy_score(y_train, y_predict_train_clf)\n",
        "test_accuracy_score_clf = accuracy_score(y_test, y_predict_test_clf)\n",
        "\n",
        "print(train_accuracy_score_clf)\n",
        "print(test_accuracy_score_clf)"
      ],
      "metadata": {
        "id": "71Y0-HmUGTxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One vs One classifier - SVC\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "clfoo = OneVsOneClassifier(LinearSVC(random_state=0))\n",
        "clfoo.fit(X_train, y_train)\n",
        "\n",
        "y_predict_train_clfoo = clfoo.predict(X_train)\n",
        "y_predict_test_clfoo = clfoo.predict(X_test)\n",
        "\n",
        "train_accuracy_score_clfoo = accuracy_score(y_train, y_predict_train_clfoo)\n",
        "test_accuracy_score_clfoo = accuracy_score(y_test, y_predict_test_clfoo)\n",
        "\n",
        "print(train_accuracy_score_clfoo)\n",
        "print(test_accuracy_score_clfoo)"
      ],
      "metadata": {
        "id": "SFdZFYliGbVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One vs One classifier - Random Forest\n",
        "clforf = OneVsOneClassifier(RandomForestClassifier(random_state=0))\n",
        "clforf.fit(X_train, y_train)\n",
        "\n",
        "y_predict_train_clforf = clforf.predict(X_train)\n",
        "y_predict_test_clforf = clforf.predict(X_test)\n",
        "\n",
        "train_accuracy_score_clforf = accuracy_score(y_train, y_predict_train_clforf)\n",
        "test_accuracy_score_clforf = accuracy_score(y_test, y_predict_test_clforf)\n",
        "\n",
        "print(train_accuracy_score_clforf)\n",
        "print(test_accuracy_score_clforf)"
      ],
      "metadata": {
        "id": "L_bZEEiAOAew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One vs One classifier - LogisticRegression\n",
        "clfolr = OneVsOneClassifier(LogisticRegression(random_state=0))\n",
        "clfolr.fit(X_train, y_train)\n",
        "\n",
        "y_predict_train_clfolr = clfolr.predict(X_train)\n",
        "y_predict_test_clfolr = clfolr.predict(X_test)\n",
        "\n",
        "train_accuracy_score_clfolr = accuracy_score(y_train, y_predict_train_clfolr)\n",
        "test_accuracy_score_clfolr = accuracy_score(y_test, y_predict_test_clfolr)\n",
        "\n",
        "print(train_accuracy_score_clfolr)\n",
        "print(test_accuracy_score_clfolr)"
      ],
      "metadata": {
        "id": "n5n548P9ZIBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OutputCode classifier - SVC\n",
        "from sklearn.multiclass import OutputCodeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "clfoc = OutputCodeClassifier(LinearSVC(random_state=0),\n",
        "                       code_size=2, random_state=0)\n",
        "clfoc.fit(X_train, y_train)\n",
        "\n",
        "y_predict_train_clfoc = clfoc.predict(X_train)\n",
        "y_predict_test_clfoc = clfoc.predict(X_test)\n",
        "\n",
        "train_accuracy_score_clfoc = accuracy_score(y_train, y_predict_train_clfoc)\n",
        "test_accuracy_score_clfoc = accuracy_score(y_test, y_predict_test_clfoc)\n",
        "\n",
        "print(train_accuracy_score_clfoc)\n",
        "print(test_accuracy_score_clfoc)"
      ],
      "metadata": {
        "id": "FgKVDajAHI2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OutputCode Classifier - Random Forest Classifier\n",
        "clfrf = OutputCodeClassifier(RandomForestClassifier(random_state=0, n_estimators=200, max_depth=50),\n",
        "                       code_size=2, random_state=0)\n",
        "clfrf.fit(X_train, y_train)\n",
        "y_predict_train_clfrf = clfrf.predict(X_train)\n",
        "y_predict_test_clfrf = clfrf.predict(X_test)\n",
        "\n",
        "train_accuracy_score_clfrf = accuracy_score(y_train, y_predict_train_clfrf)\n",
        "test_accuracy_score_clfrf = accuracy_score(y_test, y_predict_test_clfrf)\n",
        "\n",
        "print(train_accuracy_score_clfrf)\n",
        "print(test_accuracy_score_clfrf)"
      ],
      "metadata": {
        "id": "rMq7FLMeG2y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OutputCode Classifier - logisticRegression\n",
        "clflr = OutputCodeClassifier(LogisticRegression(random_state=42),\n",
        "                       code_size=2, random_state=0)\n",
        "clflr.fit(X_train, y_train)\n",
        "y_predict_train_clflr = clflr.predict(X_train)\n",
        "y_predict_test_clflr = clflr.predict(X_test)\n",
        "\n",
        "train_accuracy_score_clflr = accuracy_score(y_train, y_predict_train_clflr)\n",
        "test_accuracy_score_clflr = accuracy_score(y_test, y_predict_test_clflr)\n",
        "\n",
        "print(train_accuracy_score_clflr)\n",
        "print(test_accuracy_score_clflr)"
      ],
      "metadata": {
        "id": "xCIgXnx9PWGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "xgb = XGBClassifier()\n",
        "xgb_params = {\"n_estimators\": [50, 100, 200],\n",
        "              \"subsample\": [0.5, 0.8, 1],\n",
        "              \"max_depth\":[3, 5, 7],\n",
        "              \"learning_rate\":[0.1, 0.01, 0.3]}\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "xgb_cv_model = GridSearchCV(xgb, xgb_params, cv=3, n_jobs= -1, verbose=2).fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "EHwqb2qTfbJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_cv_model.best_params_"
      ],
      "metadata": {
        "id": "eopOVlixhJX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_tuned = XGBClassifier(learning_rate = 0.1, \n",
        "                           max_depth=5, \n",
        "                           n_estimators= 50, \n",
        "                           subsample= 0.8).fit(X_train, y_train)\n",
        "                           \n",
        "y_predict_train_xgb = xgb_tuned.predict(X_train)\n",
        "y_predict_test_xgb = xgb_tuned.predict(X_test)\n",
        "\n",
        "train_accuracy_score_xgb = accuracy_score(y_train, y_predict_train_xgb)\n",
        "test_accuracy_score_xgb = accuracy_score(y_test, y_predict_test_xgb)\n",
        "\n",
        "print(train_accuracy_score_xgb)\n",
        "print(test_accuracy_score_xgb)"
      ],
      "metadata": {
        "id": "FtCG-tnRvymi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_predict_test_xgb))"
      ],
      "metadata": {
        "id": "3sbD3vj9weYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import plot_importance\n",
        "plot_importance(xgb_tuned)"
      ],
      "metadata": {
        "id": "r24i1e_um1W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target EMA label encoder\n",
        "y_ema = df.iloc[:, 26]\n",
        "le = LabelEncoder()\n",
        "y_t = le.fit_transform(y_ema)\n",
        "\n",
        "y_Exunique = np.unique(y_ema)\n",
        "y_ExTunique = np.unique(y_t)\n",
        "y_encode = dict(zip(y_Exunique, y_ExTunique))\n",
        "print(y_encode)\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y_t, test_size=0.2)\n",
        "\n",
        "xgb_tuned = XGBClassifier(learning_rate = 0.1, \n",
        "                           max_depth=5, \n",
        "                           n_estimators= 50, \n",
        "                           subsample= 0.8).fit(X_train, y_train)\n",
        "                           \n",
        "y_predict_train_xgb = xgb_tuned.predict(X_train)\n",
        "y_predict_test_xgb = xgb_tuned.predict(X_test)\n",
        "\n",
        "train_accuracy_score_xgb = accuracy_score(y_train, y_predict_train_xgb)\n",
        "test_accuracy_score_xgb = accuracy_score(y_test, y_predict_test_xgb)\n",
        "\n",
        "print(train_accuracy_score_xgb)\n",
        "print(test_accuracy_score_xgb)"
      ],
      "metadata": {
        "id": "Lilw6Py-x989"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_predict_test_xgb))"
      ],
      "metadata": {
        "id": "MBxKuslNzRe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import plot_importance\n",
        "plot_importance(xgb_tuned)"
      ],
      "metadata": {
        "id": "Rl4gPANNm0Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target BF label encoder\n",
        "y_bf = df.iloc[:, 27]\n",
        "le = LabelEncoder()\n",
        "y_t = le.fit_transform(y_bf)\n",
        "\n",
        "y_Exunique = np.unique(y_bf)\n",
        "y_ExTunique = np.unique(y_t)\n",
        "y_encode = dict(zip(y_Exunique, y_ExTunique))\n",
        "print(y_encode)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y_t, test_size=0.2)\n",
        "\n",
        "xgb_tuned = XGBClassifier(learning_rate = 0.1, \n",
        "                           max_depth=5, \n",
        "                           n_estimators= 50, \n",
        "                           subsample= 0.8).fit(X_train, y_train)\n",
        "                           \n",
        "y_predict_train_xgb = xgb_tuned.predict(X_train)\n",
        "y_predict_test_xgb = xgb_tuned.predict(X_test)\n",
        "\n",
        "train_accuracy_score_xgb = accuracy_score(y_train, y_predict_train_xgb)\n",
        "test_accuracy_score_xgb = accuracy_score(y_test, y_predict_test_xgb)\n",
        "\n",
        "print(train_accuracy_score_xgb)\n",
        "print(test_accuracy_score_xgb)"
      ],
      "metadata": {
        "id": "8W9tOdCDytB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_predict_test_xgb))"
      ],
      "metadata": {
        "id": "tf-4vWe2zSi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import plot_importance\n",
        "plot_importance(xgb_tuned)"
      ],
      "metadata": {
        "id": "Uj59TjwQmzMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target MS label encoder\n",
        "y_ms = df.iloc[:, 28]\n",
        "le = LabelEncoder()\n",
        "y_t = le.fit_transform(y_ms)\n",
        "\n",
        "y_Exunique = np.unique(y_ms)\n",
        "y_ExTunique = np.unique(y_t)\n",
        "y_encode = dict(zip(y_Exunique, y_ExTunique))\n",
        "print(y_encode)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y_t, test_size=0.2)\n",
        "\n",
        "xgb_tuned = XGBClassifier(learning_rate = 0.1, \n",
        "                           max_depth=5, \n",
        "                           n_estimators= 50, \n",
        "                           subsample= 0.8).fit(X_train, y_train)\n",
        "                           \n",
        "y_predict_train_xgb = xgb_tuned.predict(X_train)\n",
        "y_predict_test_xgb = xgb_tuned.predict(X_test)\n",
        "\n",
        "train_accuracy_score_xgb = accuracy_score(y_train, y_predict_train_xgb)\n",
        "test_accuracy_score_xgb = accuracy_score(y_test, y_predict_test_xgb)\n",
        "\n",
        "print(train_accuracy_score_xgb)\n",
        "print(test_accuracy_score_xgb)"
      ],
      "metadata": {
        "id": "UuJz80suzCo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_predict_test_xgb))"
      ],
      "metadata": {
        "id": "-6SH9lIKzTz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import plot_importance\n",
        "plot_importance(xgb_tuned)"
      ],
      "metadata": {
        "id": "HgVSQJYdmxN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target Tprice label encoder\n",
        "y_tp = df.iloc[:, 29]\n",
        "le = LabelEncoder()\n",
        "y_t = le.fit_transform(y_tp)\n",
        "\n",
        "y_Exunique = np.unique(y_tp)\n",
        "y_ExTunique = np.unique(y_t)\n",
        "y_encode = dict(zip(y_Exunique, y_ExTunique))\n",
        "print(y_encode)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y_t, test_size=0.2)\n",
        "\n",
        "xgb_tuned = XGBClassifier(learning_rate = 0.1, \n",
        "                           max_depth=5, \n",
        "                           n_estimators= 50, \n",
        "                           subsample= 0.8).fit(X_train, y_train)\n",
        "                           \n",
        "y_predict_train_xgb = xgb_tuned.predict(X_train)\n",
        "y_predict_test_xgb = xgb_tuned.predict(X_test)\n",
        "\n",
        "train_accuracy_score_xgb = accuracy_score(y_train, y_predict_train_xgb)\n",
        "test_accuracy_score_xgb = accuracy_score(y_test, y_predict_test_xgb)\n",
        "\n",
        "print(train_accuracy_score_xgb)\n",
        "print(test_accuracy_score_xgb)"
      ],
      "metadata": {
        "id": "-RCNjrxszews"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_predict_test_xgb))"
      ],
      "metadata": {
        "id": "Bydt7kGVzxnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import plot_importance\n",
        "plot_importance(xgb_tuned)"
      ],
      "metadata": {
        "id": "qzNFeU2CmLiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiclassifier and Multioutput classfer with Random Forest model comparsion\n",
        "from beautifultable import BeautifulTable\n",
        "table = BeautifulTable()\n",
        "table.column_headers = ['Model with Random Forest','train_accuracy', 'test_accuracy']\n",
        "table.append_row(['Multiclass_OnevsRest', '0.989', '0.3930'])\n",
        "table.append_row(['Multiclass_OnevsOne', '0.989', '0.3933'])\n",
        "table.append_row(['Multiclass_Outputcode', '0.989', '0.4034'])\n",
        "table.append_row(['Multiclass_Outputclassification', '0.93', '0.003'])\n",
        "\n",
        "print(table)"
      ],
      "metadata": {
        "id": "gDifp965ISeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi classifier with logistic model comparsion\n",
        "from beautifultable import BeautifulTable\n",
        "table = BeautifulTable()\n",
        "table.column_headers = ['Model with LogisticRegression','train_accuracy', 'test_accuracy']\n",
        "table.append_row(['Multiclass_OnevsRest', '0.4193', '0.4139'])\n",
        "table.append_row(['Multiclass_OnevsOne', '0.4196', '0.4139'])\n",
        "table.append_row(['Multiclass_Outputcode', '0.4172', '0.4133'])\n",
        "\n",
        "\n",
        "print(table)"
      ],
      "metadata": {
        "id": "Olhd7QtSHEz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBclassifier model by each target value\n",
        "from beautifultable import BeautifulTable\n",
        "table = BeautifulTable()\n",
        "table.column_headers = ['target value','train_accuracy', 'test_accuracy']\n",
        "table.append_row(['CW', '0.437', '0.416'])\n",
        "table.append_row(['EMA', '0.372', '0.343'])\n",
        "table.append_row(['BF', '0.258', '0.214'])\n",
        "table.append_row(['MS', '0.423', '0.405'])\n",
        "table.append_row(['Tprice', '0.342', '0.317'])\n",
        "\n",
        "print(table)"
      ],
      "metadata": {
        "id": "xz8mresxxqiB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}